{
  "id": "finger_vein_identification_using_convolutional_neural_network_and_supervised_discrete_hashing",
  "title": "Finger vein identification using Convolutional Neural Network and supervised discrete hashing",
  "authors": [
    "CihuiXie",
    "AjayKumar"
  ],
  "content": "Automated personal identification using unique anatomical characteristics of humans is widely employed for e-governance, border crossing security and a range of e -business applications. There has been significant increase in the detection of surgically altered fingerprints, fake iris stamps, or the usage of sophisticated face masks, during the last decade. Vascular biometrics identification, like using finger vein images, can help to preserve the integrity of biometrics system as it's extremely difficult to surgically alter vascular biometrics. Another advantage with the usage of finger vein image based identification lies in the enhanced anonymity during personal authentication as the subsurface vascular patterns are largely hidden underneath and difficult to steal or imaged under visible illumination. The possibility of personal identification using vascular patterns imaged by the light transmitted through hands was indicated in 1992 [18] but was not demonstrated until 20 0 0 [19] . Such earliest work demonstrated feasibility of finger vein identification using the normalized-cross correlation. Miura et al. [9] later introduced repeated line tracking approach to improve the performance of finger vein identification, and they further enhanced the performance with maximum curvature [2] . Kumar and Zhou [4] introduced ear-liest publicly accessible finger-vein images database and comparatively evaluated range the effectiveness of hand-crafted features for the finger-vein identification. The method introduced in [4] using Gabor filter based enhancement and morphological operations is still regarded the best performing methods for matching fingervein images. A range of other hand-crafted finger vein features [2,4,9,[11][12][13][14][15]20] , primarily obtained from the careful evaluation of the registered images, have been attempted in the literature with very promising results. Multiple features acquired from the two cameras [13] or using multiple feature extractors [17] can be combined to significantly improve the performance for the vascular biometrics matching. One of the limitations of finger-vein identification methods introduced in the literature is related to their large template size. Smaller template size is highly desirable to reduce storage and/or enhance the matching speed for the online applications. There have also been successful attempts to reduce the finger-vein template size, like in [11,14] or recently in [12] using sparse representation of enhanced finger-vein images using the Gabor filters. Table 1 presents summary of some promising methods for finger vein matching in the literature. This table also presents the template size in the respective reference (several of these have been estimated from details provided in respective reference), performance in terms of EER and the database used for the performance evaluation. The last two rows in this table summarize best performing results from our investigation detailed in this work.  The key objective of this work is to investigate and develop advanced capabilities for matching finger-vein images using deep learning. Section 2 details preprocessing and image enhancement steps incorporated in the experiments for evaluating effectiveness of various CNN architectures which are detailed in Section 3 . The supervised hashing is introduced in Section 4 while the experimental protocols and results [21] are discussed in Section 5 . The discussion on some of our findings appears is Section 6 . The key conclusions from this paper are summarized in Section 7 . Finger vein image acquisition can introduce translational and rotational changes among the different images from the same finger or subject. Therefore, automated extraction of fixed region of interest (ROI) that can minimize such intra-class variations is highly desirable. The method of ROI localization considered in our work is same as detailed in [4] . Fig. 1 illustrates acquired image sample, extracted ROI and the image sample after enhancement to improve the image contrast (as detailed in [4] . The vascular patterns in the normalized image samples can be further enhanced by spatial filtering from orientation selective band pass filters, similar as employed for the enhancement of fingerprint ridges. We also attempted to ascertain usefulness of such enhanced finger vein images using the Gabor filters. These filters from the twelve different orientations are selected to generate enhanced finger vein images as shown in Fig. 2 . Such enhanced images using Gabor filters are effective in accentuating the vascular features and therefore its possible usage in automatically learning features from CNN was also investigated in the experiments. Several successful models for the deep learning have been developed to learn useful feature representation but largely for the face biometric image patterns. A variety of such models using CNN have been introduced in the literature and were investigated to ascertain performance for the finger vein image matching. A brief introduction to various CNN architectures considered in this work is provided in the following sections. The light CNN (LCNN) framework introduces a Max-Feature-Map (MFM) operation [3] between convolutional layers which establishes a competitive relationship for superior generalization capability and reduces parameter space (compact feature representation). Such maxout activation function ( Fig. 3 ) significantly reduces the complexity and makes CNN lighter. The architecture of LCNN employed in our experiments is shown in Fig. 4 (MFM part is excluded to maintain the clarity). The network contains 9 convolutional layers (conv), 4 pooling layers (pooling) and 2 fully connected layers (fc) and some assistant layers. Deep Siamese networks have been successfully incorporated in the literature to learn a similarity metric between a pair of images. We incorporated triplet similarity loss function as detailed in [6] for LCNN to learn the similarity metric. We randomly select an image x r from training set as random sample in Fig. 5 . Then we choose image x p which is from the same class referred to as positive sample and image x n which is from a different class referred to as negative. After LCNN, we get the features f ( x r ), f ( x n ) and f ( x p ). Our objective is to decrease the similarity distance between random and positive features, and increase it between random and negative features, which indicates why it's named as triplet similarity loss. At the same time, we need to ensure there is a sufficient margin between them. Suppose we have a random set X r = { x r i } N i =1 and its correspond- . Considering these notations, we can write our loss function as follows: where [] + represents that we maintain positive values and change others to zero. The detailed architecture of LCNN with such triplet loss function is shown in Fig. 5 and Table 2 . When the set of input consists of n random samples, n positives and n negatives, we generate 3 n × 500 features. These pairs were split into three parts, each with the size of n × 500, and used as the input for computing triplet loss for updating the neuron weights during the network training. The Visual Geometry Group architecture with 16 layers (VGG-16) [7] was modified for the CNN to directly recover the match scores, instead of the feature vectors, in our experiment. Our modification was motivated to fit the rectangular finger vein ROI images without introducing the distortions. We used pair of images rather than single image as the input in conventional VGG-16 since we wanted to compare the similarity of two finger vein images. The input image size is also different from conventional VGG-16, which is 224 × 224, while its 128 × 488 pixels for our finger vein ROI images. The training phase utilized the cross-entropy loss function which can be written as follows: - where is the logistic function, x i is the extracted feature and w is the weight that needs optimized during training. The architecture of Modified VGG-16 (MVGG) is illustrated in the following Fig. 6 . One of the key challenges for the successful usage of biometrics technologies are related to efficient search speed (fast retrieval) and template storage/size. Hashing is one of the most effective approaches to address such challenges and can efficiently encode the biometrics templates using binary numbers (20 0 0 in our experiments) that closely reflect the similarity with input data/templates. With such strategy we can only store the corresponding short/compact binary codes, instead of original feature templates, and significantly improve the search or the matching speed by highly efficient pairwise comparison using the Hamming distance. This framework for an effective supervised hashing scheme is introduced in [1] and the objective in the learning phase is to generate binary codes for the linear classification. We firstly define the problem and assume that we have n samples/features X = [ x 1 x 2 . . . x n ] , and our goal is to recover corre- 1 , 2 , . . . , n . Since we have labels, in order to make good use of these information, we define a multi-class classification function: where C is the total number of classes, and y ∈ R C× 1 is the label vector, where the maximum one indicates its class of input x . Now we can formulate the hashing problem as follows: where L ( • ) represents the loss function used by us which is the L2-norm in our experiments, λ is the regularization parameter, and at the same time, b i is generated by the hash function sgn( F ( x i )), where sgn( • ) is the sign function. With the help of Lagrange Multiplier, we then can rewrite (4) as: where μ is the Lagrange multiplier. We further select a non-linear form of function for F ( x ): where U is the parameter matrix and φ( x ) is a k-dimensional kernel that a j , j = 1 , 2 , . . . , k , are randomly selected anchor vectors from input. In order to compute U in the function, we can rewrite (4) as following format: where (X ) = { φ( x i ) } n i =1 and our purpose is to set the gradient to zero, which is It is simpler to achieve the final computation for U as follows. In order to solve for W , we make use of the same method, first simplify (4) to min 11) and then calculate its gradient based on W which can be set as zero and we get Finally we can solve for B , we exclude those variables which have no relation to B and then rewrite (4) as follows. or can be further simplified as follows. min cating that B 2 is some constant. We can now solve this problem bit-by-bit . Let p T represent the l th row of B , and B is the matrix without p T . Similarly let v T be the l th row of W , and let q T be the l th row of Q , where Q = F (X ) + WY , then we can ignore W and Q . While moving a row to the end for all matrices would not cause problems, to better understand the problem. In order to enhance clarity of the problem, we can move all the l th row to the end and rewrite B = [ B p T ] T , and the same for W and Q . We can then rewrite first term in (15) as follows. While tr Combining these terms, we can rewrite (15) as follows. min This is an optimization problem, and p ∈ { -1 , 1 } n , therefore we just need to incorporate the opposite sign of its first argument. We can now explicitly outline computed parts in the following. Shen et al. [1] have provided another computation based on the hinge loss. However for the simplicity, we incorporated L2-norm in our experiments and therefore this part has been excluded here. We now have the required equations here and can summarize our algorithm as follows. This section provides details on the experiments performed using various CNN architectures discussed in previous sections. In order to ensure reproducibility of experimental results, we utilized publicly available two session database [5] . This database of 6264 images has been acquired from 156 different subjects and includes finger-vein images from two fingers for each subject. However, the second session images are only from 105 different subjects. In our experiments we only used first session images to train different network architectures discussed in previous section, and excluded 51 subjects without second session. The experimental results are presented using second session test data. Therefore each of the receiver operating characteristics uses 1260 (210 × 6) genuine scores and 263,340 (210 × 209 × 6) impostor scores. We experimented on ROI images, enhanced ROI images and even Gabor filtered images separately. ROI images have 256 × 513 pixels, enhanced ROI images have 218 × 488 pixels and even Gabor filtered images have 218 × 488 pixels. The experimental results using ROC and CMC from the respective CNN architecture are presented in the following. We firstly performed the experiments for the CNN trained using the ROI images, enhanced ROI images and the enhanced images using Gabor filters ( Fig. 1 and2 ). The experimental results using respective second session dataset are shown in Fig. 7 . The respective ROC in this figure illustrates that enhanced i mages can achieve superior matching performance than those from using ROI images. The enhancement of ROI images using Gabor filters significantly helps to suppress the noisy pixels and accentuate the vascular regions and is the plausible reason for superior accuracy. The experimental results using LCNN trained with Siamese triplet similarity loss function are presented in Fig. 8 . These results consistently illustrate superior performance using this architecture than the LCNN. The performance from the ROC of enhanced ROI with Gabor filters is superior and this observation is in line with the trends observed from results using LCNN in the Fig. 7 . LCNN without triplet similarity loss tries to match a sample with its label, while LCNN with the similarity loss focuses on similarities between the images, this is the likely reason for the superior ROC performance. Another scheme that has recently shown superior performance for the ocular identification in [10] uses joint Bayesian [8] , instead of L2 norm, as the metrics for the similarity. The LCNN with the joint Bayesian classification scheme was also attempted to ascertain the performance. The ROC using this approach is illustrated in Fig. 9 and indicates notable performance improvement over LCNN. The supervised discrete hashing (SDH) scheme detailed in Section 4 was also investigated for the performance improvement. Only first session data was employed for the training part and employed for generating the binarized bits that were used for computing match score using the Hamming distance. The resulting ROC in Fig. 10 illustrates consistent performance improvement with the usage of SDH and the trends in the usage of enhanced ROI images are also consistent with our earlier observations. The LCNN trained with triplet similarity loss function was also employed used with the SDH to evaluate the performance. We attempted to ascertain the performance with different number of bits. Higher number of bits for SDH can be generally expected to offer superior results but requires more training time. It should be noted that this method is actually a second-step training, and tries to map features from the Euclidian space to the binary space. The training phase and hamming distance metrics can contribute to its superior performance. The combination of CNN with the hashing to reduce for the faster and real-time identification has also been attempted earlier [16] but for the face recognition problem. Authors in [16] incorporated Boosted Hashing Forest (BHF) for the hashing and therefore we also attempted to incorporate such BHF scheme to comparatively evaluate the performance. However, our results illustrated superiority of SDH over BHF and the template size using BHF was also fixed to 20 0 0 bits. Although our results did not achieve significant improvement in the performance using BHF, its usage can help in remarkably reducing the template size.  In order to as-certain comparative performance for matching finger vein images using the hand-crafted features, we also performed additional experiments. The ROC from the same test images and matching protocols but using Repeated line tracking [8] (also used as baseline method in [15] ) and maximum curvatures [2] method is illustrated in Fig. 11 . We can observe from these experimental results that using SDH and LCNN can offer superior performance and significantly reduce the template size. Our results over the method using [4] are can be considered as competing and not yet superior but offers significantly reduced template size ( ∼26 times smaller) over the best of the methods in [4] . The experimental results using modified VGG-16, as detailed in Section 3.3 are presented in Fig. 12 . It should be noted that this CNN architecture generates single match score and therefore prohibits use from using the SDH scheme to the infer features. We can infer from the ROCs that the modified VGG-16 architecture generates superior performance for matching finger-vein images as com-  pared with the network trained using LCNN. This structure generates matching scores directly, the problem of feature space is excluded, which may be a convincible reason for its superior results. Since we used both finger-vein images from two fingers to form larger dataset (as in [4] ) for above experiments, it is judicious to ascertain the performance when only one, i.e ., index or middle, finger vein images are used in the training and test phase. The results using respective finger-vein images from 105 different subjects are comparatively shown in Fig. 13 using the ROC. The performance using the images from both fingers (using 210 class formed by combination of index and middle finger for 105 different subjects) is superior to single finger, and index finger shows better performance than middle finger. Similar trends are also observed while using hand crafted features in [4] and can be attributed to the nature of imaging or the dataset. In earlier experiments, the first session data had images acquired from the same subjects who were providing their images during the second session and were used as test set for the performance. In order to ascertain robustness of self-learned features using the best scheme so far, we also evaluated the performance from the independent 51 subjects in this dataset which did not have any two-session finger-vein images. Therefore images from none of these subjects images were employed during the training for CNN in any of the earlier experiments. The six images from these 51 subjects were used to ascertain performance using challenging protocol, i.e ., all-to-all, so that we generated a total of 1530 genuine scores and 185,436 impostor scores to ascertain such performance. The ROC corresponding to this independent test subjects finger vein data is shown in Fig. 14 and the results indicate promising performance from the self-learned features using a model trained (in Section 3.2 and SDH) for matching finger-vein images from unknown subjects. This paper has investigated finger vein matching performance using Convolutional Neural Network architectures. Unlike earlier work on finger vein image matching which largely employed hand crafted features, our emphasis has been to investigate automatically learned features using the capabilities of deep learning. We systematically investigated the performance improvement using just the ROI images and the systematically enhanced images that mainly emphasizes on subsurface vascular network. Our results consistently indicate superior performance from the CNN that are trained with images which have such enhanced vascular features. According to our experimental results in Section 5.6 , modified VGG-16 (MVGG) achieves superior performance than LCNN. However MVGG requires significantly higher time for the training (also for the test phase). This can be largely attributed to the fact that it directly generates the match scores and therefore the loss function outputs propagate iteratively through the whole network to ascertain the similarity between a pair of finger vein images. At the same time, we cannot incorporate SDH (hashing scheme) with the MVGG, due to non-availability of intermediate features, while the usage of SDH has shown to offer remarkable improvement in the performance. It should be noted that the triplet similarity loss function helps to significantly improve the experimental performance using the LCNN. However, this approach cannot adequately make use of the label information, because it attempts to decrease the feature similarity between the pairwise images from the same subject, but cannot accurately locate the labels, i.e ., identity of the subjects they are associated with. Supervised discrete hashing approach further improves the performance and retrieval speed, and decrease the storage which requires only 250 bytes (20 0 0 bits) for the one template (feature vector). However, it should also be noted that this method needs a separate training phase and training time rapidly increases when the bit length or number of features are increased. In this context, it is possible to incorporate recently introduced end-to-end learning schemes that incorporate deep neural networks to hash the features for fast image retrieval or matching [24][25][26] . Therefore, we also attempted to ascertain the performance from such deep supervised hashing scheme detailed in [25] . In order to ensure fairness in the comparison with SDH or two-step training model, same training data was used for training and test phase. Fig. 15 illustrates comparative performance with the CNN based deep supervised hashing and our SDH scheme detailed in Section 4 . These results indicate that two step training model using SDH can achieve superior performance for matching the finger vein images. The plausible reason for poor performance from deep supervised hashing scheme lies in the lack of sufficient training data for our problem as we are attempting to directly map 210 class data, with high intra-class variations, into 500 or more bits. However with our two-step approach, the first step from CNN helps to extract useful information and therefore the second step with SDH received better input to consolidate the output into smaller number of bits. The work detailed in this paper also had several constraints and therefore should be considered only preliminary. The database employed, although one of the largest two session finger vein database available in public domain, is still of smaller size for the deep learning based algorithms. There are several references in the literature that have shown promising performance but yet to demonstrate superior matching performance over the method in [4] using fair comparison or the same matching protocols. Therefore, we are justified in using the performance from [4] , for this publicly available dataset, as the reference. This paper has investigated finger vein matching performance using various Convolutional Neural Network architectures. Unlike earlier work on finger vein matching which employed hand crafted features, our emphasis has been to investigate performance from the automatically learned features using the capabilities of deep learning. We systematically investigated the performance improvement using the ROI finger vein images, and the enhances images and consistently observed that the usage of ROI images with enhanced vascular features and attenuation of background (noise) can significantly improve the performance. The factors that most influence the accuracy of matching finger vein images is the depth of the network, the pre-training and the data augmentation in terms of random crops and rotations. The usage of supervised discrete hashing with a Siamese network trained using the triplet loss function achieves most accurate performance among the all architectures considered in this work. The usage of hashing also significantly reduces the template size, to 20 0 0 bits, for every subject and is the key advantage of this approach over other methods for finger vein matching available in the literature. The matching accuracy using this scheme also achieves outperforming results as compared with baseline methods considered in this work. The work detailed in this work also had several constraints and therefore should be considered only preliminary. The database employed, although the largest two session finger vein images database available in public domain, is still of smaller size for the deep learning algorithms. Larger size database is expected to result in better learning of the representative features. One possibility is to use synthesized finger vein images, such as those generated in [22] , to enrich the learning phase and should be carefully considered in further work. Further work should also be directed to develop deep learning architectures for finger vein images that can directly recover binary codes, e.g . [23] , and achieve efficient matching. More baseline methods, instead of just two in this work, should be selected for the comparison with the performance using the hand crafted methods and is part of our ongoing work in this area. * Computed by us from the details available in the respective reference.",
  "filePath": "C:\\Users\\Alex Isaev\\Documents\\truth source\\citation-verifier\\src\\document-database\\pdf-documents\\1-s2.0-S0167865517304397-main.pdf",
  "year": "2018",
  "doi": "10.1016/j.patrec.2017.12.001"
}